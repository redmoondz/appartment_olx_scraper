# OLX Apartment Scraper

Асинхронный парсер объявлений об аренде квартир с сайта OLX.ua с кешированием, логированием и CLI интерфейсом.

## Возможности

- ✅ **Асинхронный сбор данных** - быстрая параллельная обработка страниц
- ✅ **Кеширование в CSV** - сохранение всех собранных данных
- ✅ **Обнаружение новых постов** - автоматическое сравнение с кешем
- ✅ **Гибкая настройка агрессивности** - от медленного (1) до быстрого (10) режима
- ✅ **Подробное логирование** - все операции записываются в logs/
- ✅ **CLI интерфейс** - удобное управление через командную строку
- ✅ **Retry механизм** - автоматические повторные попытки при ошибках
- ✅ **Rich форматирование** - красивый вывод таблиц и прогресса

## Установка

1. Клонируйте репозиторий:
```bash
git clone <repository-url>
cd appartment_scraper
```

2. Создайте виртуальное окружение:
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# или
venv\Scripts\activate  # Windows
```

3. Установите зависимости:
```bash
pip install -r requirements.txt
```

4. Инициализируйте конфигурацию:
```bash
python main.py init
```

5. Отредактируйте `.env` файл под ваши нужды.

## Использование

### Основные команды

#### Запуск парсера

```bash
# Базовый запуск с настройками по умолчанию
python main.py scrape

# Парсинг только первых 5 страниц
python main.py scrape -p 5

# Сохранение только новых объявлений
python main.py scrape -n

# Быстрый режим (агрессивность 8)
python main.py scrape -a 8

# Медленный режим (агрессивность 2)
python main.py scrape -a 2

# Комбинация опций
python main.py scrape -p 10 -n -a 7
```

#### Просмотр статистики

```bash
python main.py stats
```

#### Экспорт данных

```bash
# Экспорт с автоматическим именем файла
python main.py export

# Экспорт в конкретный файл
python main.py export -o my_apartments.csv
```

#### Очистка кеша

```bash
python main.py clear-cache
```

### Параметры агрессивности

Уровень агрессивности (1-10) определяет скорость работы парсера:

- **1-3**: Медленный режим - большие задержки между запросами, минимальный риск блокировки
- **4-6**: Умеренный режим - баланс между скоростью и безопасностью (рекомендуется)
- **7-10**: Быстрый режим - минимальные задержки, максимальная скорость

## Структура проекта

```
appartment_scraper/
├── cache/                      # Кеш данных (CSV)
│   └── apartments_cache.csv
├── data/                       # Экспортированные данные
├── logs/                       # Логи работы
│   └── olx_scraper_YYYYMMDD.log
├── src/
│   ├── core/
│   │   ├── olx_api.py         # Клиент для работы с OLX
│   │   └── cache.py           # Менеджер кеша
│   ├── utils/
│   │   ├── config.py          # Конфигурация
│   │   └── logger.py          # Настройка логирования
│   ├── models.py              # Модели данных
│   └── scraper.py             # Основной оркестратор
├── cli.py                      # CLI интерфейс
├── main.py                     # Точка входа
├── requirements.txt            # Зависимости
├── .env.example               # Пример конфигурации
└── README.md                   # Документация
```

## Собираемые данные

Для каждой квартиры собираются следующие поля:

- `post_id` - Уникальный ID объявления
- `name` - Название объявления
- `price` - Цена аренды
- `currency` - Валюта (UAH, USD, EUR)
- `location` - Местоположение (город, район)
- `district` - Район города
- `total_area` - Общая площадь (м²)
- `rooms` - Количество комнат
- `floor` - Этаж
- `total_floors` - Этажность здания
- `furnished` - Наличие мебели
- `description` - Описание
- `contact_phone` - Контактный телефон
- `photos` - Массив URL фотографий
- `url` - Ссылка на объявление
- `created_date` - Дата создания
- `watch_count` - Количество просмотров
- `tags` - Теги/метки
- `scraped_at` - Время сбора данных

## Конфигурация

Основные параметры в `.env`:

```bash
# URLs
BASE_URL=https://www.olx.ua
SEARCH_URL=https://www.olx.ua/uk/nedvizhimost/kvartiry/...

# Лимиты запросов
MIN_REQUESTS_PER_MINUTE=10
MAX_REQUESTS_PER_MINUTE=60
DEFAULT_REQUESTS_PER_MINUTE=30

# Задержки между запросами
MIN_DELAY=1
MAX_DELAY=3

# Повторные попытки
MAX_RETRIES=3
RETRY_DELAY=5

# Параллельные воркеры
MAX_WORKERS=5

# Логирование
LOG_LEVEL=INFO
```

## Логирование

Все операции логируются в директорию `logs/`:
- Подробные логи в файле: `olx_scraper_YYYYMMDD.log`
- Ротация логов при достижении 10 МБ
- Хранение 5 последних файлов

Уровни логирования:
- **DEBUG**: Детальная информация о каждом запросе
- **INFO**: Основные события работы
- **WARNING**: Предупреждения
- **ERROR**: Ошибки с traceback

## Примеры использования

### Ежедневный мониторинг новых объявлений

```bash
# Запускайте раз в день для поиска новых квартир
python main.py scrape -n -a 5
```

### Полный сбор с нуля

```bash
# Очистите кеш и соберите все данные заново
python main.py clear-cache
python main.py scrape -a 4
```

### Быстрый сбор с экспортом

```bash
python main.py scrape -p 20 -a 8
python main.py export -o results.csv
```

## Обработка ошибок

Парсер автоматически обрабатывает:
- Сетевые ошибки с повторными попытками
- Таймауты запросов
- Ошибки парсинга HTML
- Недоступные страницы

Все ошибки логируются для последующего анализа.

## Рекомендации

1. **Не используйте максимальную агрессивность постоянно** - это может привести к блокировке
2. **Запускайте с флагом `-n`** для ежедневного мониторинга новых объявлений
3. **Проверяйте логи** при возникновении проблем
4. **Делайте резервные копии** кеша перед `clear-cache`
5. **Используйте VPN** при частых запросах

## Troubleshooting

### Парсер не находит объявления
- Проверьте правильность URL в `.env`
- Убедитесь, что сайт доступен
- Проверьте логи на наличие ошибок

### Медленная работа
- Увеличьте параметр агрессивности
- Уменьшите `MAX_DELAY` в `.env`
- Проверьте скорость интернет-соединения

### Ошибки при сохранении в кеш
- Убедитесь, что директория `cache/` доступна для записи
- Проверьте наличие свободного места на диске

## Лицензия

MIT License

## Автор

Your Name

## Поддержка

При возникновении проблем создайте issue в репозитории проекта.
